{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57f550e1",
   "metadata": {},
   "source": [
    "# Multi-Agent Retrieval-Augmented Generation (RAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Graph Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph:\n",
    "    def __init__(self, START):\n",
    "        self.START = START\n",
    "\n",
    "    def start(self):\n",
    "        self.START.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, name=None):\n",
    "        self.name = name\n",
    "\n",
    "    def run(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(Node):\n",
    "    def __init__(self, condition, name=None): \n",
    "        super().__init__(name)\n",
    "        self.condition = condition\n",
    "        self.yes = None\n",
    "        self.no = None\n",
    "\n",
    "    def add_yes(self, node):\n",
    "        self.yes = node\n",
    "\n",
    "    def add_no(self, node):\n",
    "        self.no = node\n",
    "    \n",
    "    def run(self):\n",
    "        print(f\"--Agent {self.name} Called--\")\n",
    "        if self.condition():\n",
    "            self.yes.run()\n",
    "        else:\n",
    "            self.no.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tool(Node):\n",
    "    def __init__(self, action, name=None): \n",
    "        super().__init__(name)\n",
    "        self.action = action\n",
    "    \n",
    "    def run(self):\n",
    "        print(f\"--Tool {self.name} Called--\")\n",
    "        self.action()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Multi-Agent RAG with above Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"Enter your API Key\")\n",
    "\n",
    "llm = genai.GenerativeModel(\"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sample inputs\n",
    "\n",
    "question = \"What is langchain?\"\n",
    "document_text = \"LangChain is a framework designed to help developers create applications powered by language models. It provides tools to connect LLMs with external sources of data and create complex workflows.\"\n",
    "\n",
    "# question = \"What is langchain?\"\n",
    "# document_text = \"\"\n",
    "\n",
    "# question = \"What is google?\"\n",
    "# document_text = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the document contains enough information to answer the question\n",
    "def can_answer_question():\n",
    "    # Define a prompt to check if the question can be answered\n",
    "\n",
    "    # \"Does the document contain enough information to answer the question? \" \\\n",
    "    check_prompt = f\"Document: {document_text}\\n\\nQuestion: {question}\\n\\n\" \\\n",
    "                   \"Can you answer the above question with or without the given document? \" \\\n",
    "                   \"Respond with 'yes' or 'no'.\"\n",
    "\n",
    "    response = llm.generate_content(check_prompt).text\n",
    "    print(response)\n",
    "    if \"yes\" in response.lower():\n",
    "        return True # document contains sufficient information\n",
    "    else:\n",
    "        return False # document lacks sufficient information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate an answer if the document is sufficient\n",
    "def generate_answer():\n",
    "    # Define a prompt to generate the answer based on the document\n",
    "    answer_prompt = f\"Document: {document_text}\\n\\nQuestion: {question}\\n\\nAnswer:\"\n",
    "    answer = llm.generate_content(answer_prompt)\n",
    "    print(answer.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_google():\n",
    "    #  Search Google for the answer\n",
    "    print(\"Searching Google for the answer...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent1 = Agent(condition=lambda: can_answer_question(), name = \"Agent1\")\n",
    "generate = Tool(action=lambda: generate_answer(), name = \"Generate\")\n",
    "search = Tool(action=lambda: search_google(), name=\"Google Search\")\n",
    "\n",
    "agent1.add_yes(generate)\n",
    "agent1.add_no(search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Graph(START=agent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Agent Agent1 Called--\n",
      "yes \n",
      "\n",
      "--Tool Generate Called--\n",
      "LangChain is a framework that helps developers build applications powered by language models. It connects LLMs with external data sources and allows for the creation of complex workflows. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "graph.start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
