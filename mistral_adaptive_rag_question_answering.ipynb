{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-colab"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pathwaycom/pathway/blob/main/examples/notebooks/showcases/mistral_adaptive_rag_question_answering.ipynb\" target=\"_parent\"><img src=\"https://pathway.com/assets/colab-badge.svg\" alt=\"Run In Colab\" class=\"inline\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "notebook-instructions",
      "metadata": {},
      "source": [
        "# Installing Pathway with Python 3.10+\n",
        "\n",
        "In the cell below, we install Pathway into a Python 3.10+ Linux runtime.\n",
        "\n",
        "> **If you are running in Google Colab, please run the colab notebook (Ctrl+F9)**, disregarding the 'not authored by Google' warning.\n",
        "> \n",
        "> **The installation and loading time is less than 1 minute**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "pip-installation-pathway",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture --no-display\n",
        "%pip install --prefer-binary pathway"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "logging",
      "metadata": {},
      "outputs": [],
      "source": [
        "import logging\n",
        "\n",
        "logging.basicConfig(level=logging.CRITICAL)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4",
      "metadata": {},
      "source": [
        "# Private RAG with Connected Data Sources using Mistral, Ollama, and Pathway"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5",
      "metadata": {
        "lines_to_next_cell": 2
      },
      "source": [
        "Retrieval-Augmented Generation (RAG) is a powerful way to answer questions based on your own, private, knowledge database. However, data security is key: sensitive information like trade secrets, confidential IP, GDPR-protected data, and internal documents that cannot be entrusted to third parties.\n",
        "\n",
        "Most of the existing RAG solutions rely on LLM APIs that send your data, or at least a part of it, to the LLM provider. For example, if your RAG solution uses ChatGPT, you will have to send your data to OpenAI through OpenAI API.\n",
        "\n",
        "Fortunately, there is a solution to keep your data private: deploying a local LLM. By deploying everything locally, your data remains secure within your own infrastructure. This eliminates the risk of sensitive information ever leaving your control.\n",
        "\n",
        "While this seems quite an engineering feat, don't worry. Pathway and Ollama provide you with everything you need to make this as easy as possible.\n",
        "\n",
        "In this showcase, you will learn how to set up a private RAG pipeline with adaptive retrieval using Pathway, Mistral, and Ollama.\n",
        "The pipeline answers questions from the Stanford Question Answering Dataset [(SQUAD)](https://rajpurkar.github.io/SQuAD-explorer/) using a selection of Wikipedia pages from the same dataset as the context, split into paragraphs.\n",
        "**This RAG pipeline runs without any API access or any data leaving the local machine with Pathway**.\n",
        "\n",
        "The architecture consists of two connected technology bricks, which will run as services on your machine:\n",
        "- Pathway brings support for real-time data synchronization pipelines out of the box, and the possibility of secure private document handling with enterprise connectors for synchronizing Sharepoint and Google Drive incrementally. The Pathway service we run will perform our live document indexing pipeline, and will use Pathway’s built-in vector store.\n",
        "\n",
        "- The language model we use will be a Mistral 7B, which we will locally deploy as an Ollama service. This model was chosen for its performance and compact size.\n",
        "\n",
        "![Reference architecture](https://pathway.com/assets/content/blog/local-adaptive-rag/local_adaptive.png)\n",
        "\n",
        "You will explore how to use Pathway to:\n",
        "- connect a document source\n",
        "- perform document indexing\n",
        "- connect to our local LLM\n",
        "- prompt our LLM with relevant context, and adaptively add more documents as needed\n",
        "- combine everything, and orchestrate the RAG pipeline with Pathway.\n",
        "\n",
        "If you are not familiar with the Pathway yet, you can refer to the [overview of Pathway's LLM xpack](https://pathway.com/developers/user-guide/llm-xpack/overview) and [its documentation](https://pathway.com/developers/api-docs/pathway-xpacks-llm/llms)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6",
      "metadata": {
        "lines_to_next_cell": 2
      },
      "source": [
        "## What is Private RAG and Why Do You Need It?\n",
        "\n",
        "Most of the RAG applications require you to send your documents & data to propriety APIs. This is a concern for most organizations as data privacy with sensitive documents becomes an issue. Generally, you need to send your documents during the indexing and LLM question-answering stages.\n",
        "\n",
        "To tackle this, you can use a **private RAG: locally deployed LLMs and embedders in your RAG pipeline**.\n",
        "\n",
        "### Why use Local LLMs?\n",
        "\n",
        "There are several advantages to using local LLMs (Large Language Models) over cloud-based APIs:\n",
        "- **Data Privacy**: Local LLMs keep your sensitive data on your machines.\n",
        "- **Accuracy**: Cloud-based LLM accuracy is not always optimal and can also sometimes regress during upgrades, whereas local models provide predictable performance and can also be fine-tuned for better accuracy.\n",
        "- **Customization**: Local LLMs fine-tuning allows you to achieve specific behaviors or domain adaptation.\n",
        "\n",
        "### Mistral and Ollama for privacy\n",
        "\n",
        "**Mistral 7B** is publicly available LLM model release by [Mistral AI](https://mistral.ai/).\n",
        "Its (relative) small size of 7.3B parameters and impressive performances make Mistral 7B a perfect candidate for a local deployment.\n",
        "\n",
        "The pipeline relies on **Ollama** to deploy the Mistral 7B model.\n",
        "[Ollama](https://ollama.com/) is a tool to create, manage, and run LLM models.\n",
        "Ollama is used to download and configure locally the Mistral 7B model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7",
      "metadata": {
        "lines_to_next_cell": 2
      },
      "source": [
        "## Private RAG with Pathway\n",
        "\n",
        "This section provides a step-by-step guide on how to set up Private RAG with Adaptive Retrieval using Pathway, a framework for building LLM applications. The guide covers:\n",
        "1. **Installation**: Installing Pathway and required libraries.\n",
        "2. **Data Loading**: Loading documents for which answer retrieval will be performed.\n",
        "3. **Embedding Model Selection**: Choosing an open-source embedding model from Hugging Face.\n",
        "4. **Local LLM Deployment**: Instructions on deploying a local LLM using Ollama, a lightweight container runtime.\n",
        "5. **LLM Initialization**: Setting up the LLM instance to interact with the local model.\n",
        "6. **Vector Document Index Creation**: Building an index for efficient document retrieval using the embedding model.\n",
        "7. **Retriever setup**: Defining the parameters for the context retrieval strategy for queries made to the RAG system.\n",
        "8. **Pipeline Execution**: Running the Private RAG pipeline with your data.\n",
        "\n",
        "### 1. Installation\n",
        "\n",
        "You install Pathway into a Python 3.10+ Linux runtime with a simple pip command:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8",
      "metadata": {
        "lines_to_next_cell": 2
      },
      "source": [
        "```\n",
        "!pip install -U --prefer-binary pathway\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9",
      "metadata": {},
      "source": [
        "We also install [LiteLLM](https://litellm.ai/) - a library of helpful Python wrappers for calling into our LLM. With it, we can later easily change our LLM without rewriting a lot of code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "10",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mDEPRECATION: Loading egg at /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/opt_einsum-3.4.0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/patsy-0.5.6-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/scikit_learn-1.5.2-py3.11-macosx-10.15-x86_64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/torch-2.2.2-py3.11-macosx-10.15-x86_64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/threadpoolctl-3.5.0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/joblib-1.4.2-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/networkx-3.4.1-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/pgmpy-0.1.26-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/statsmodels-0.14.4-py3.11-macosx-10.15-x86_64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/filelock-3.16.1-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/jinja2-3.1.4-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/MarkupSafe-3.0.1-py3.11-macosx-10.15-x86_64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/fsspec-2024.9.0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/sympy-1.13.3-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/mpmath-1.3.0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: litellm>=1.35 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (1.42.12)\n",
            "Requirement already satisfied: aiohttp in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from litellm>=1.35) (3.10.10)\n",
            "Requirement already satisfied: click in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from litellm>=1.35) (8.1.7)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/setuptools/_vendor (from litellm>=1.35) (8.0.0)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/jinja2-3.1.4-py3.11.egg (from litellm>=1.35) (3.1.4)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from litellm>=1.35) (4.23.0)\n",
            "Requirement already satisfied: openai>=1.27.0 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from litellm>=1.35) (1.52.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from litellm>=1.35) (2.7.4)\n",
            "Requirement already satisfied: python-dotenv>=0.2.0 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from litellm>=1.35) (1.0.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from litellm>=1.35) (2.32.3)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from litellm>=1.35) (0.8.0)\n",
            "Requirement already satisfied: tokenizers in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from litellm>=1.35) (0.20.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/setuptools/_vendor (from importlib-metadata>=6.8.0->litellm>=1.35) (3.19.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/MarkupSafe-3.0.1-py3.11-macosx-10.15-x86_64.egg (from jinja2<4.0.0,>=3.1.2->litellm>=1.35) (3.0.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.35) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.35) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.35) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.35) (0.20.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from openai>=1.27.0->litellm>=1.35) (4.6.2.post1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from openai>=1.27.0->litellm>=1.35) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from openai>=1.27.0->litellm>=1.35) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from openai>=1.27.0->litellm>=1.35) (0.6.1)\n",
            "Requirement already satisfied: sniffio in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from openai>=1.27.0->litellm>=1.35) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from openai>=1.27.0->litellm>=1.35) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from openai>=1.27.0->litellm>=1.35) (4.11.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.0.0->litellm>=1.35) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.0.0->litellm>=1.35) (2.18.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.31.0->litellm>=1.35) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.31.0->litellm>=1.35) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.31.0->litellm>=1.35) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.31.0->litellm>=1.35) (2024.8.30)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from tiktoken>=0.7.0->litellm>=1.35) (2024.9.11)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from aiohttp->litellm>=1.35) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from aiohttp->litellm>=1.35) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from aiohttp->litellm>=1.35) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from aiohttp->litellm>=1.35) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from aiohttp->litellm>=1.35) (1.15.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from tokenizers->litellm>=1.35) (0.26.1)\n",
            "Requirement already satisfied: httpcore==1.* in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai>=1.27.0->litellm>=1.35) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.27.0->litellm>=1.35) (0.14.0)\n",
            "Requirement already satisfied: filelock in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/filelock-3.16.1-py3.11.egg (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.35) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/fsspec-2024.9.0-py3.11.egg (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.35) (2024.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.35) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.35) (6.0.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from yarl<2.0,>=1.12.0->aiohttp->litellm>=1.35) (0.2.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install \"litellm>=1.35\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11",
      "metadata": {},
      "source": [
        "Lastly, we install [Sentence-Transformers](https://sbert.net/) for embedding the chunked texts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "12",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mDEPRECATION: Loading egg at /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/opt_einsum-3.4.0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/patsy-0.5.6-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/scikit_learn-1.5.2-py3.11-macosx-10.15-x86_64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/torch-2.2.2-py3.11-macosx-10.15-x86_64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/threadpoolctl-3.5.0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/joblib-1.4.2-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/networkx-3.4.1-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/pgmpy-0.1.26-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/statsmodels-0.14.4-py3.11-macosx-10.15-x86_64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/filelock-3.16.1-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/jinja2-3.1.4-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/MarkupSafe-3.0.1-py3.11-macosx-10.15-x86_64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/fsspec-2024.9.0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/sympy-1.13.3-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/mpmath-1.3.0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting sentence-transformers\n",
            "  Downloading sentence_transformers-3.2.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
            "  Downloading transformers-4.45.2-py3-none-any.whl.metadata (44 kB)\n",
            "Requirement already satisfied: tqdm in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from sentence-transformers) (4.66.5)\n",
            "Requirement already satisfied: torch>=1.11.0 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/torch-2.2.2-py3.11-macosx-10.15-x86_64.egg (from sentence-transformers) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/scikit_learn-1.5.2-py3.11-macosx-10.15-x86_64.egg (from sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from sentence-transformers) (1.12.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from sentence-transformers) (0.26.1)\n",
            "Requirement already satisfied: Pillow in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from sentence-transformers) (11.0.0)\n",
            "Requirement already satisfied: filelock in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/filelock-3.16.1-py3.11.egg (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/fsspec-2024.9.0-py3.11.egg (from huggingface-hub>=0.20.0->sentence-transformers) (2024.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.11.0)\n",
            "Requirement already satisfied: sympy in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/sympy-1.13.3-py3.11.egg (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/networkx-3.4.1-py3.11.egg (from torch>=1.11.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: jinja2 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/jinja2-3.1.4-py3.11.egg (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
            "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
            "  Downloading safetensors-0.4.5-cp311-cp311-macosx_10_12_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/joblib-1.4.2-py3.11.egg (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/threadpoolctl-3.5.0-py3.11.egg (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/MarkupSafe-3.0.1-py3.11-macosx-10.15-x86_64.egg (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/mpmath-1.3.0-py3.11.egg (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Downloading sentence_transformers-3.2.1-py3-none-any.whl (255 kB)\n",
            "Downloading transformers-4.45.2-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading safetensors-0.4.5-cp311-cp311-macosx_10_12_x86_64.whl (392 kB)\n",
            "Installing collected packages: safetensors, transformers, sentence-transformers\n",
            "Successfully installed safetensors-0.4.5 sentence-transformers-3.2.1 transformers-4.45.2\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install sentence-transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13",
      "metadata": {
        "lines_to_next_cell": 2
      },
      "source": [
        "### 2. Data Loading\n",
        "We will start by testing our solution with a static sample of knowledge data. We have prepared a sample for download for use in the  [adaptive-rag-contexts.jsonl](https://public-pathway-releases.s3.eu-central-1.amazonaws.com/data/adaptive-rag-contexts.jsonl) file, with ~1000 contexts from the SQUAD dataset, taken from Wikipedia texts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "14",
      "metadata": {
        "lines_to_next_cell": 2
      },
      "outputs": [],
      "source": [
        "!wget -q -nc https://public-pathway-releases.s3.eu-central-1.amazonaws.com/data/adaptive-rag-contexts.jsonl"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15",
      "metadata": {},
      "source": [
        "Next, let’s do the necessary imports."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "16",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<script type=\"esms-options\">{\"shimMode\": true}</script><style>*[data-root-id],\n",
              "*[data-root-id] > * {\n",
              "  box-sizing: border-box;\n",
              "  font-family: var(--jp-ui-font-family);\n",
              "  font-size: var(--jp-ui-font-size1);\n",
              "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
              "}\n",
              "\n",
              "/* Override VSCode background color */\n",
              ".cell-output-ipywidget-background:has(\n",
              "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
              "  ),\n",
              ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
              "  background-color: transparent !important;\n",
              "}\n",
              "</style>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n  const py_version = '3.6.0'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  const reloading = false;\n  const Bokeh = root.Bokeh;\n\n  // Set a timeout for this load but only if we are not already initializing\n  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      // Don't load bokeh if it is still initializing\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      // There is nothing to load\n      run_callbacks();\n      return null;\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error(e) {\n      const src_el = e.srcElement\n      console.error(\"failed to load \" + (src_el.href || src_el.src));\n    }\n\n    const skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'tabulator': 'https://cdn.jsdelivr.net/npm/tabulator-tables@6.2.1/dist/js/tabulator.min', 'moment': 'https://cdn.jsdelivr.net/npm/luxon/build/global/luxon.min'}, 'shim': {}});\n      require([\"tabulator\"], function(Tabulator) {\n        window.Tabulator = Tabulator\n        on_load()\n      })\n      require([\"moment\"], function(moment) {\n        window.moment = moment\n        on_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 2;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    const existing_stylesheets = []\n    const links = document.getElementsByTagName('link')\n    for (let i = 0; i < links.length; i++) {\n      const link = links[i]\n      if (link.href != null) {\n        existing_stylesheets.push(link.href)\n      }\n    }\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const escaped = encodeURI(url)\n      if (existing_stylesheets.indexOf(escaped) !== -1) {\n        on_load()\n        continue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window.Tabulator !== undefined) && (!(window.Tabulator instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.5.2/dist/bundled/datatabulator/tabulator-tables@6.2.1/dist/js/tabulator.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(encodeURI(urls[i]))\n      }\n    }    if (((window.moment !== undefined) && (!(window.moment instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.5.2/dist/bundled/datatabulator/luxon/build/global/luxon.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(encodeURI(urls[i]))\n      }\n    }    var existing_scripts = []\n    const scripts = document.getElementsByTagName('script')\n    for (let i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n        existing_scripts.push(script.src)\n      }\n    }\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (let i = 0; i < js_modules.length; i++) {\n      const url = js_modules[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      const url = js_exports[name];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.holoviz.org/panel/1.5.2/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\", \"https://cdn.holoviz.org/panel/1.5.2/dist/bundled/datatabulator/tabulator-tables@6.2.1/dist/js/tabulator.min.js\", \"https://cdn.holoviz.org/panel/1.5.2/dist/bundled/datatabulator/luxon/build/global/luxon.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-3.6.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.6.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.6.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.6.0.min.js\", \"https://cdn.holoviz.org/panel/1.5.2/dist/panel.min.js\"];\n  const js_modules = [];\n  const js_exports = {};\n  const css_urls = [\"https://cdn.holoviz.org/panel/1.5.2/dist/bundled/datatabulator/tabulator-tables@6.2.1/dist/css/tabulator_simple.min.css?v=1.5.2\"];\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (let i = 0; i < inline_js.length; i++) {\n        try {\n          inline_js[i].call(root, root.Bokeh);\n        } catch(e) {\n          if (!reloading) {\n            throw e;\n          }\n        }\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n        var NewBokeh = root.Bokeh;\n        if (Bokeh.versions === undefined) {\n          Bokeh.versions = new Map();\n        }\n        if (NewBokeh.version !== Bokeh.version) {\n          Bokeh.versions.set(NewBokeh.version, NewBokeh)\n        }\n        root.Bokeh = Bokeh;\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      // If the timeout and bokeh was not successfully loaded we reset\n      // everything and try loading again\n      root._bokeh_timeout = Date.now() + 5000;\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      root._bokeh_is_loading = 0\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      const bokeh_loaded = root.Bokeh != null && (root.Bokeh.version === py_version || (root.Bokeh.versions !== undefined && root.Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n        if (root.Bokeh) {\n          root.Bokeh = undefined;\n        }\n        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n        run_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
            "application/vnd.holoviews_load.v0+json": ""
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
            "application/vnd.holoviews_load.v0+json": ""
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.holoviews_exec.v0+json": "",
            "text/html": [
              "<div id='dc7a87f2-b96c-4814-a99f-79c8bddf3035'>\n",
              "  <div id=\"f60cd7e7-4a54-4aed-88fa-85fceb733987\" data-root-id=\"dc7a87f2-b96c-4814-a99f-79c8bddf3035\" style=\"display: contents;\"></div>\n",
              "</div>\n",
              "<script type=\"application/javascript\">(function(root) {\n",
              "  var docs_json = {\"53aeaef6-c214-41e8-88c0-214db145a987\":{\"version\":\"3.6.0\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"dc7a87f2-b96c-4814-a99f-79c8bddf3035\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"e36c5be7-7a63-4c44-ae19-cba08de9afc4\",\"attributes\":{\"plot_id\":\"dc7a87f2-b96c-4814-a99f-79c8bddf3035\",\"comm_id\":\"9c1d4e943d9541818610a783940958f9\",\"client_comm_id\":\"0bb180135338429ead80febb6f61a16e\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"ReactiveESM1\"},{\"type\":\"model\",\"name\":\"JSComponent1\"},{\"type\":\"model\",\"name\":\"ReactComponent1\"},{\"type\":\"model\",\"name\":\"AnyWidgetComponent1\"},{\"type\":\"model\",\"name\":\"request_value1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"_synced\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_request_sync\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
              "  var render_items = [{\"docid\":\"53aeaef6-c214-41e8-88c0-214db145a987\",\"roots\":{\"dc7a87f2-b96c-4814-a99f-79c8bddf3035\":\"f60cd7e7-4a54-4aed-88fa-85fceb733987\"},\"root_ids\":[\"dc7a87f2-b96c-4814-a99f-79c8bddf3035\"]}];\n",
              "  var docs = Object.values(docs_json)\n",
              "  if (!docs) {\n",
              "    return\n",
              "  }\n",
              "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
              "  async function embed_document(root) {\n",
              "    var Bokeh = get_bokeh(root)\n",
              "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
              "    for (const render_item of render_items) {\n",
              "      for (const root_id of render_item.root_ids) {\n",
              "\tconst id_el = document.getElementById(root_id)\n",
              "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
              "\t  const root_el = id_el.children[0]\n",
              "\t  root_el.id = root_el.id + '-rendered'\n",
              "\t  for (const child of root_el.children) {\n",
              "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
              "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
              "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
              "\t  }\n",
              "\t}\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "  function get_bokeh(root) {\n",
              "    if (root.Bokeh === undefined) {\n",
              "      return null\n",
              "    } else if (root.Bokeh.version !== py_version) {\n",
              "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
              "\treturn null\n",
              "      }\n",
              "      return root.Bokeh.versions.get(py_version);\n",
              "    } else if (root.Bokeh.version === py_version) {\n",
              "      return root.Bokeh\n",
              "    }\n",
              "    return null\n",
              "  }\n",
              "  function is_loaded(root) {\n",
              "    var Bokeh = get_bokeh(root)\n",
              "    return (Bokeh != null && Bokeh.Panel !== undefined && ( root.Tabulator !== undefined) && ( root.Tabulator !== undefined))\n",
              "  }\n",
              "  if (is_loaded(root)) {\n",
              "    embed_document(root);\n",
              "  } else {\n",
              "    var attempts = 0;\n",
              "    var timer = setInterval(function(root) {\n",
              "      if (is_loaded(root)) {\n",
              "        clearInterval(timer);\n",
              "        embed_document(root);\n",
              "      } else if (document.readyState == \"complete\") {\n",
              "        attempts++;\n",
              "        if (attempts > 200) {\n",
              "          clearInterval(timer);\n",
              "\t  var Bokeh = get_bokeh(root)\n",
              "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
              "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
              "\t  } else {\n",
              "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
              "\t    embed_document(root)\n",
              "\t  }\n",
              "        }\n",
              "      }\n",
              "    }, 25, root)\n",
              "  }\n",
              "})(window);</script>"
            ]
          },
          "metadata": {
            "application/vnd.holoviews_exec.v0+json": {
              "id": "dc7a87f2-b96c-4814-a99f-79c8bddf3035"
            }
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import pathway as pw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "17",
      "metadata": {},
      "outputs": [],
      "source": [
        "# To use advanced features with Pathway Scale, get your free license key from\n",
        "# https://pathway.com/features and paste it below.\n",
        "# To use Pathway Community, comment out the line below.\n",
        "pw.set_license_key(\"demo-license-key-with-telemetry\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "18",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathway.stdlib.indexing import default_vector_document_index\n",
        "from pathway.xpacks.llm import embedders\n",
        "from pathway.xpacks.llm.llms import LiteLLMChat\n",
        "from pathway.xpacks.llm.question_answering import (\n",
        "    answer_with_geometric_rag_strategy_from_index,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "19",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load documents in which answers will be searched\n",
        "class InputSchema(pw.Schema):\n",
        "    doc: str\n",
        "\n",
        "\n",
        "documents = pw.io.fs.read(\n",
        "    \"adaptive-rag-contexts.jsonl\",\n",
        "    format=\"json\",\n",
        "    schema=InputSchema,\n",
        "    json_field_paths={\"doc\": \"/context\"},\n",
        "    mode=\"static\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20",
      "metadata": {},
      "source": [
        "When testing during development, we can run this code in a \"static\" way and check if all the sources are correctly loaded. Later, in production, the Pathway service running our code will know how to refresh the loaded documents when new data arrives."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21",
      "metadata": {},
      "outputs": [],
      "source": [
        "# check if documents are correctly loaded\n",
        "# documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "22",
      "metadata": {
        "lines_to_next_cell": 2
      },
      "outputs": [],
      "source": [
        "# Create a table with example questions\n",
        "df = pd.DataFrame(\n",
        "    {\n",
        "        \"query\": [\n",
        "            \"When it is burned what does hydrogen make?\",\n",
        "            \"What was undertaken in 2010 to determine where dogs originated from?\",\n",
        "            # \"What did Arnold's journey into politics look like?\",\n",
        "        ]\n",
        "    }\n",
        ")\n",
        "query = pw.debug.table_from_pandas(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23",
      "metadata": {
        "lines_to_next_cell": 2
      },
      "source": [
        "### 3. Embedding Model Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24",
      "metadata": {
        "lines_to_next_cell": 2
      },
      "source": [
        "We use `pathway.xpacks.llm.embedders` module to load open-source embedding models from the HuggingFace model library. For our showcase, we pick the `avsolatorio/GIST-small-Embedding-v0` model which has a dimension of 384."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "25",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding dimension: 384\n"
          ]
        }
      ],
      "source": [
        "embedding_model = \"avsolatorio/GIST-small-Embedding-v0\"\n",
        "\n",
        "embedder = embedders.SentenceTransformerEmbedder(\n",
        "    embedding_model, call_kwargs={\"show_progress_bar\": False}\n",
        ")  # disable verbose logs\n",
        "embedding_dimension: int = embedder.get_embedding_dimension()\n",
        "print(\"Embedding dimension:\", embedding_dimension)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26",
      "metadata": {},
      "source": [
        "We have picked the avsolatorio/GIST-small-Embedding-v0 model as it is compact and performed well in our tests. If you would like to use a higher-dimensional model, here are some possible alternatives you could use instead:\n",
        "\n",
        "- `mixedbread-ai/mxbai-embed-large-v1`\n",
        "- `avsolatorio/GIST-Embedding-v0`\n",
        "\n",
        "For other possible choices, take a look at the [MTEB Leaderboard](https://huggingface.co/spaces/mteb/leaderboard) managed by HuggingFace.\n",
        "\n",
        "Model embedding can take some CPU power. In case you have access to limited computation on your development machines, for tests, you can also start by using an embedder service over public API. For example, Mistral offers such a service - to use it, instead of the local embedding code above, you would uncomment the following API code.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27",
      "metadata": {},
      "outputs": [],
      "source": [
        "# embedder = LiteLLMEmbedder(\n",
        "#     capacity = 5,\n",
        "#     retry_strategy = pw.udfs.ExponentialBackoffRetryStrategy(max_retries=4, initial_delay=1200),\n",
        "#     model = \"mistral/mistral-embed\",\n",
        "#     api_key=<mistral_api_key>,\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28",
      "metadata": {
        "lines_to_next_cell": 2
      },
      "source": [
        "#### 4. Local LLM Deployement\n",
        "Due to its size and performance we decided to run the `Mistral 7B` Local Language Model. We deploy it as a service running on GPU, using `Ollama`.\n",
        "\n",
        "In order to run local LLM, refer to these steps:\n",
        "- Download Ollama from [ollama.com/download](https://ollama.com/download)\n",
        "- In your terminal, run `ollama serve`\n",
        "- In another terminal, run `ollama run mistral`\n",
        "\n",
        "You can now test it with the following:\n",
        "\n",
        "```bash\n",
        "curl -X POST http://localhost:11434/api/generate -d '{\n",
        "  \"model\": \"mistral\",\n",
        "  \"prompt\":\"Here is a story about llamas eating grass\"\n",
        " }'\n",
        "```\n",
        "\n",
        "Notice that here we are working on localhost. You could potentially run the Ollama and Pathway services on different machines as the RAG pipeline and LLM will communicate over API. We will not do it in this showcase, but you may consider such a possibility, for example, to run just one LLM service on a single GPU, and then connect multiple RAG pipelines running on different virtual machines to it."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29",
      "metadata": {},
      "source": [
        "### 5. LLM Initialization\n",
        "\n",
        "We now initialize the LLM instance that will call our local model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "30",
      "metadata": {
        "lines_to_next_cell": 2
      },
      "outputs": [],
      "source": [
        "model = LiteLLMChat(\n",
        "    model=\"ollama/mistral\",\n",
        "    temperature=0,\n",
        "    top_p=1,\n",
        "    api_base=\"http://localhost:11434\",  # local deployment\n",
        "    format=\"json\",  # only available in Ollama local deploy, do not use in Mistral API\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31",
      "metadata": {},
      "source": [
        "In the above, by putting `format=\"json\"` we specifically instructed LLM to return outputs in json format. In this format, the LLM follows instructions more strictly. This is only needed for some LLM's; for example, we would not need it if we used mistral-large, or GPT-4."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32",
      "metadata": {
        "lines_to_next_cell": 2
      },
      "source": [
        "### 6. Vector Document Index Creation\n",
        "We continue our pipeline code to specify the index with documents and embedding model to use when processing documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "33",
      "metadata": {
        "lines_to_next_cell": 2
      },
      "outputs": [],
      "source": [
        "index = default_vector_document_index(\n",
        "    documents.doc, documents, embedder=embedder, dimensions=embedding_dimension\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34",
      "metadata": {
        "lines_to_next_cell": 2
      },
      "source": [
        "### 7. Retriever setup\n",
        "Here, we specify to our Pathway service how to retrieve relevant context from the vector index for a user query. Pathway offers several retrieval strategies to choose from, which offer a lot of flexibility in configuring e.g. how many of the relevant chunks to retrieve into the LLM’s context, and in what order to rank them.\n",
        "\n",
        "A simple choice could be to pick the top-k retriever, which retrieves the top k chunks most relevant to a query, like this (for example, we could ask to retrieve k=10 chunks) and answer questions based on these chunks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35",
      "metadata": {},
      "source": [
        "Here, let’s take full advantage of what Pathway has to offer, and take a smarter top-k retriever called Adaptive RAG which adapts the number of chunks k as needed, by asking the LLM if it has received enough context already or still needs more. It’s just a single line to set up the hyperparameters, and in practice, this will often make your local LLM reply faster, sometimes consuming even 4x less tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "36",
      "metadata": {
        "lines_to_next_cell": 2
      },
      "outputs": [],
      "source": [
        "result = query.select(\n",
        "    question=query.query,\n",
        "    result=answer_with_geometric_rag_strategy_from_index(\n",
        "        query.query,\n",
        "        index,\n",
        "        documents.doc,\n",
        "        model,\n",
        "        n_starting_documents=2,\n",
        "        factor=2,\n",
        "        max_iterations=4,\n",
        "        strict_prompt=True,  # needed for open source models, instructs LLM to give JSON output strictly\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37",
      "metadata": {
        "lines_to_next_cell": 2
      },
      "source": [
        "### 8. Pipeline Execution\n",
        "When testing locally, you can run the pipeline once and print the results table with `pw.debug.compute_and_print`. Remember the questions we put originally in the `query` table?  (They were: “When it is burned what does hydrogen make?\", \"What was undertaken in 2010 to determine where dogs originated from?\"). Now, we are ready to get the answers based on all the knowledge in our current dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "38",
      "metadata": {
        "lines_to_next_cell": 2
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
            "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "thread 'pathway:work-0' panicked at src/engine/report_error.rs:152:14:\n",
            "APIConnectionError: litellm.APIConnectionError: 'name'\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/litellm/main.py\", line 2471, in completion\n",
            "    generator = ollama.get_ollama_response(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/litellm/llms/ollama.py\", line 293, in get_ollama_response\n",
            "    \"name\": function_call[\"name\"],\n",
            "            ~~~~~~~~~~~~~^^^^^^^^\n",
            "KeyError: 'name'\n",
            "\n",
            "OpenTelemetry metrics error occurred. Metrics error: [ExportErr(Status { code: Cancelled, message: \", detailed error message: Timeout expired\" })]\n"
          ]
        },
        {
          "ename": "APIConnectionError",
          "evalue": "litellm.APIConnectionError: 'name'\nTraceback (most recent call last):\n  File \"/Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/litellm/main.py\", line 2471, in completion\n    generator = ollama.get_ollama_response(\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/litellm/llms/ollama.py\", line 293, in get_ollama_response\n    \"name\": function_call[\"name\"],\n            ~~~~~~~~~~~~~^^^^^^^^\nKeyError: 'name'\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAPIConnectionError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/v3/svrtr8q93tv1b1frpml03gvm0000gn/T/ipykernel_2860/2947715431.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_and_print\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/pathway/internals/runtime_type_check.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mShould\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mneeded\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mresolving\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mgithub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcom\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbeartype\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbeartype\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0missues\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m234\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \"\"\"\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mbeartype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeartype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32mexcept\u001b[0m \u001b[0mbeartype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBeartypeCallHintParamViolation\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<@beartype(pathway.debug.compute_and_print) at 0x12b7aeac0>\u001b[0m in \u001b[0;36m?\u001b[0;34m(__beartype_func, __beartype_conf, __beartype_get_violation, __beartype_object_140181221262464, __beartype_object_5124535744, __beartype_object_4398490528, *args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m~/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/pathway/internals/trace.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pathway_trace_marker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0m_reraise_with_user_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/pathway/internals/trace.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(e, trace)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muser_frame\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0madd_pathway_trace_note\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_frame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/pathway/debug/__init__.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(include_id, short_pointers, n_rows, *tables, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0minclude_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0mto\u001b[0m \u001b[0mshow\u001b[0m \u001b[0mids\u001b[0m \u001b[0mof\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0mshort_pointers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0mto\u001b[0m \u001b[0mshorten\u001b[0m \u001b[0mprinted\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mn_rows\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0mrows\u001b[0m \u001b[0mto\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0mwhole\u001b[0m \u001b[0mtable\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mprinted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \"\"\"\n\u001b[0;32m--> 215\u001b[0;31m     _compute_and_print_internal(\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0msquash_updates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0minclude_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/pathway/debug/__init__.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(squash_updates, include_id, short_pointers, n_rows, _stacklevel, *tables, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0mn_rows\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0m_stacklevel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m ) -> None:\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mcaptured\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_compute_tables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_stacklevel\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mget_pathway_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_id\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"0\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_single\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/pathway/internals/runtime_type_check.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mShould\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mneeded\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mresolving\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mgithub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcom\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbeartype\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbeartype\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0missues\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m234\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \"\"\"\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mbeartype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeartype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32mexcept\u001b[0m \u001b[0mbeartype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBeartypeCallHintParamViolation\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<@beartype(pathway.debug._compute_tables) at 0x1222f8cc0>\u001b[0m in \u001b[0;36m?\u001b[0;34m(__beartype_func, __beartype_conf, __beartype_get_violation, __beartype_object_140181221262464, __beartype_object_140181216963008, __beartype_getrandbits, *args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m~/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/pathway/debug/__init__.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(_stacklevel, *tables, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mcheck_arg_types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m def _compute_tables(\n\u001b[1;32m     49\u001b[0m     \u001b[0;34m*\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m ) -> list[api.CapturedStream]:\n\u001b[0;32m---> 51\u001b[0;31m     captured = GraphRunner(\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mparse_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mmonitoring_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMonitoringLevel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNONE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/pathway/internals/graph_runner/__init__.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, after_build, *tables)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mafter_build\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mScopeState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOperatorStorageGraph\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     ) -> list[api.CapturedStream]:\n\u001b[1;32m    101\u001b[0m         \u001b[0mnodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_shake_tables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_scope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_tables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mafter_build\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mafter_build\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/pathway/internals/graph_runner/__init__.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, nodes, output_tables, after_build, run_all)\u001b[0m\n\u001b[1;32m    225\u001b[0m                                 \u001b[0mline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                                 \u001b[0mfunction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                             ),\n\u001b[1;32m    228\u001b[0m                         )\n\u001b[0;32m--> 229\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/pathway/internals/udfs/utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mevent_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_event_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mevent_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"event loop should be running\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mpfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mevent_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_in_executor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpfunc\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/concurrent/futures/thread.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;31m# Break a reference cycle with the exception 'exc'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/pathway/xpacks/llm/llms.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, messages, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmessages_decoded\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         }\n\u001b[1;32m    395\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         ret = litellm.completion(\n\u001b[0m\u001b[1;32m    398\u001b[0m             \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessages_decoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         )  # temporarily disable async due to behavior difference while using `json` mode with Ollama\n\u001b[1;32m    400\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"message\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"content\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/litellm/utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1025\u001b[0m                     if (\n\u001b[1;32m   1026\u001b[0m                         \u001b[0mliteDebuggerClient\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mliteDebuggerClient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdashboard_url\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m                     ):  # make it easy to get to the debugger logs if you've initialized it\n\u001b[1;32m   1028\u001b[0m                         \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"\\n Check the log in your dashboard - {liteDebuggerClient.dashboard_url}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/litellm/utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1025\u001b[0m                     if (\n\u001b[1;32m   1026\u001b[0m                         \u001b[0mliteDebuggerClient\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mliteDebuggerClient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdashboard_url\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m                     ):  # make it easy to get to the debugger logs if you've initialized it\n\u001b[1;32m   1028\u001b[0m                         \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"\\n Check the log in your dashboard - {liteDebuggerClient.dashboard_url}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/litellm/main.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_tokens, presence_penalty, frequency_penalty, logit_bias, user, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, **kwargs)\u001b[0m\n\u001b[1;32m   2757\u001b[0m             )\n\u001b[1;32m   2758\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2759\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2760\u001b[0m         \u001b[0;31m## Map to OpenAI Exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2761\u001b[0;31m         raise exception_type(\n\u001b[0m\u001b[1;32m   2762\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2763\u001b[0m             \u001b[0mcustom_llm_provider\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_llm_provider\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2764\u001b[0m             \u001b[0moriginal_exception\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/litellm/utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[0m\n\u001b[1;32m   8164\u001b[0m         ):\n\u001b[1;32m   8165\u001b[0m             \u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mThread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_all_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_provider\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8166\u001b[0m         \u001b[0;31m# don't let an error with mapping interrupt the user from receiving an error from the llm api calls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexception_mapping_worked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8168\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8169\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8170\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0merror_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlitellm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLITELLM_EXCEPTION_TYPES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8171\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/litellm/utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[0m\n\u001b[1;32m   8164\u001b[0m         ):\n\u001b[1;32m   8165\u001b[0m             \u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mThread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_all_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_provider\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8166\u001b[0m         \u001b[0;31m# don't let an error with mapping interrupt the user from receiving an error from the llm api calls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexception_mapping_worked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8168\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8169\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8170\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0merror_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlitellm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLITELLM_EXCEPTION_TYPES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8171\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAPIConnectionError\u001b[0m: litellm.APIConnectionError: 'name'\nTraceback (most recent call last):\n  File \"/Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/litellm/main.py\", line 2471, in completion\n    generator = ollama.get_ollama_response(\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/arushigarg/Desktop/sem_5/Honeywell Analysis/.conda/lib/python3.11/site-packages/litellm/llms/ollama.py\", line 293, in get_ollama_response\n    \"name\": function_call[\"name\"],\n            ~~~~~~~~~~~~~^^^^^^^^\nKeyError: 'name'\n",
            "\u001b[0mOccurred here:\n    Line: pw.debug.compute_and_print(result)\n    File: /var/folders/v3/svrtr8q93tv1b1frpml03gvm0000gn/T/ipykernel_2860/2947715431.py:1"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
            "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "pw.debug.compute_and_print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39",
      "metadata": {},
      "source": [
        "# Going to Production"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40",
      "metadata": {},
      "source": [
        "Now you have a fully private RAG set up with Pathway and Ollama. All your data remains safe on your system. Moreover, the set-up is optimized for speed, thanks to how Ollama runs the LLM, and how Pathway’s adaptive retrieval mechanism reduces token consumption while preserving the accuracy of the RAG.\n",
        "\n",
        "We can now go further by building and deploying your RAG application in production with Pathway, including updating data in constant connection with data sources and serving the endpoints 24/7. All the code logic we have built so far can be used directly!\n",
        "\n",
        "For a full production-ready set-up, we have built a slightly larger RAG application demonstrator which also includes reading your data sources, parsing the data, and serving the endpoint. To get started, check it out [here](https://github.com/pathwaycom/llm-app/tree/main/examples/pipelines/private-rag).\n",
        "You will find easy-to-follow setup instructions in our [question answering demo](https://github.com/pathwaycom/llm-app/tree/main/examples/pipelines/demo-question-answering).\n",
        "\n",
        "Enjoy your fully private RAG application!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41",
      "metadata": {},
      "source": [
        "# Key Takeaways"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42",
      "metadata": {},
      "source": [
        "In this showcase, you have learned how to design a fully local and private RAG setup, including a local embedder and LLM. We built our RAG pipeline as Python code using  Pathway ensuring that the necessary privacy is maintained at every step of the RAG pipeline. We finally showed how to use Pathway to orchestrate our Python code, running a service that incrementally updates our knowledge base as it changes, and answers questions with the LLM.\n",
        "\n",
        "**This private RAG setup can be run entirely locally with open-source LLMs, making it ideal for organizations with sensitive data and eXplainable AI needs.** We believe Mistral 7B with Ollama to be a good choice for the local LLM service. Still, in organizations that have already deployed local LLMs differently, the Pathway RAG pipeline may also be used with other models.\n"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
